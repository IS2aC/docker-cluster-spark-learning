![image](https://github.com/user-attachments/assets/b4618775-7268-4622-b570-aa1db7a0ee3a)

# docker-cluster-spark-learning
Let's learn with docker, how we can create a cluster spark to make transformation over our data ...

The role of a Data Engineer is often perceived as complex due to the ever-evolving tech landscape. Every week, new technologies emerge, with experts and tech advocates predicting their rise as the next big industry standard. In this highly competitive environment, one technology has remained a cornerstone for nearly 16 years: Apache Spark. Designed to tackle challenges related to data volume, velocity, and value, Spark stands out for its distributed processing capabilities, making it a game-changer in the world of data. However, getting started with this type of technology is not always easy. Why? Because despite having the motivation, setting up a ready-to-use infrastructure for hands-on learning can be quite challenging.

In this mini-tutorial, I‚Äôll show you how to leverage GitHub Codespaces and Docker to deploy your own Spark cluster and start mastering this powerful technology. Just three months ago, I had no idea what GitHub Codespaces was. For those in the same situation, it‚Äôs a free service from GitHub that can be thought of as ‚Äúvscode-as-a-Service.‚Äù Essentially, it‚Äôs a Docker-based instance of a fully managed machine that GitHub provides to the community. Today, I truly believe that not having a powerful computer is no longer a valid excuse for not learning to code. With all these accessible solutions, anyone can start coding regardless of their hardware.

Two years ago, I didn‚Äôt have a machine powerful enough to run Docker. If you‚Äôre in the same boat, GitHub Codespaces is a great alternative. But even with a standard computer, this project is completely doable.


## Prerequisites for this mini-project:
‚úÖ Docker & Docker Compose installed and running
üí° Good news: On GitHub Codespaces, Docker and Docker Compose come preinstalled by default.
‚úÖ the python library make, to simplify long command executions.

## Launch the project 
check on this medium tutorial :   <a href ='https://medium.com/@nisaacemmanuel/mini-project-own-cluster-spark-using-docker-docker-compose-f648e2e439ec' >my medium tutorial</a>
